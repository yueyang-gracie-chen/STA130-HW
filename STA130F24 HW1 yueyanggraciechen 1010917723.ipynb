{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2a6fcd",
   "metadata": {},
   "source": [
    "1. Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cdb0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30752ae7",
   "metadata": {},
   "source": [
    "2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a pandas DataFrame has, and then\n",
    "use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,\n",
    "write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9e46b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392fd760",
   "metadata": {},
   "source": [
    "Observations: An observation represents a single data point or record in a dataset, and it is always bonded with a row in the dataset. For example, in a dataset of a survey, each row represents a different individual who is asked to do the survey. And in this dataset of villagers, each row represents one villager and also contains all data about this villager. Therefore, observation represents a row in a dataset, which contains a complete instance of data for a specific individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf60e0a",
   "metadata": {},
   "source": [
    "Variables: Variables are the collection of different types of data and information for a observation, and each column in the dataset has its related variable. For example, in a survey, variables can be the questions asked for those individuals. In this dataset of villagers, variables include all types of information about the villagers, such as gender, bithday, personality, etc. Therefore, variable represents a column in a dataset, which clarifies the specific types of information for the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41c060",
   "metadata": {},
   "source": [
    "3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a57bd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db114c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "cat          23\n",
       "rabbit       20\n",
       "frog         18\n",
       "squirrel     18\n",
       "duck         17\n",
       "dog          16\n",
       "cub          16\n",
       "pig          15\n",
       "bear         15\n",
       "mouse        15\n",
       "horse        15\n",
       "bird         13\n",
       "penguin      13\n",
       "sheep        13\n",
       "elephant     11\n",
       "wolf         11\n",
       "ostrich      10\n",
       "deer         10\n",
       "eagle         9\n",
       "gorilla       9\n",
       "chicken       9\n",
       "koala         9\n",
       "goat          8\n",
       "hamster       8\n",
       "kangaroo      8\n",
       "monkey        8\n",
       "anteater      7\n",
       "hippo         7\n",
       "tiger         7\n",
       "alligator     7\n",
       "lion          7\n",
       "bull          6\n",
       "rhino         6\n",
       "cow           4\n",
       "octopus       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfed46",
   "metadata": {},
   "source": [
    "Why i use df['column'].value_counts() here is because after using the code df.describe() as chatgpt suggested me, i find there are only a few numerical variables, which makes df.describe() not that useful for me to analyse the data, so i use this code df['column'].value_counts() to help me find out the number of villagers for different species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543a9c1",
   "metadata": {},
   "source": [
    "4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f820d78",
   "metadata": {},
   "source": [
    "In the dataset with non-numeric variables and missing values in numeric variables, there can be discrepancies between size of dataset given by df.shape and the output of df.describe. Here is the explanation for the discrepancies:\n",
    "\n",
    "df.shape: The output of df.shape function is a pair of values representing the count of all rows and columns in the dataset. It includes every row and every column no matter what their data types are and no matter if there are missing values existing.\n",
    "\n",
    "df.describe(): Outputs of df.describe() show the conclusive statistics of the dataframe. When executing df.describe(), it returns a summary of the numeric columns with non-missing data by default. If you want it to return categorical columns, you should specify include=['object']. So we can see that df.describe() treats numerical and non-numerical data in seperate way and only provides summaries for columns which contain values.\n",
    "\n",
    "Examples for df.shape and df.describe() are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec5c45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d919f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df73222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>380</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>361</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>388</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>cat</td>\n",
       "      <td>1-27</td>\n",
       "      <td>lazy</td>\n",
       "      <td>K.K. Country</td>\n",
       "      <td>wee one</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     name gender species birthday personality          song  \\\n",
       "count       390      391    391     391      391         391           380   \n",
       "unique      390      391      2      35      361           8            92   \n",
       "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
       "freq          1        1    204      23        2          60            10   \n",
       "\n",
       "         phrase           full_id  \\\n",
       "count       391               391   \n",
       "unique      388               391   \n",
       "top     wee one  villager-admiral   \n",
       "freq          2                 1   \n",
       "\n",
       "                                                      url  \n",
       "count                                                 391  \n",
       "unique                                                391  \n",
       "top     https://villagerdb.com/images/villagers/thumb/...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e64f5",
   "metadata": {},
   "source": [
    "So, the number of columns will be different for df.shape and df.describe() as the total number of columns in the dataset can be shown by df.shape, while df.describe only gives a summary for numeric columns and non-missing data if you don't specify include=['object'] for non-numeric columns. Therefore, the count of columns provided by df.shape could be more than the count of columns shown by df.describe.\n",
    "\n",
    "The \"count\" will aslo exist inconsistency sometimes. The amount of non-missing values in each numeric column is represented by the \"count\" in df.describe(), which means if there is missing data in a column, the \"count\" of the column will be smaller than the total number of rows.\n",
    "\n",
    "Summary:\n",
    "df.shape returns total numbers of all rows and columns in a dataset, ignoring their data types and missing values;\n",
    "df.describe() returns only a summary for numeric columns which are non-missing by default unless you specify include=['object'] to summarize categorical data. This is also the reason for size and \"count\" discrepancies between df.shape and df.describe()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed212679",
   "metadata": {},
   "source": [
    "5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "an \"attribute\", such as df.shape which does not end with ()\n",
    "and a \"method\", such as df.describe() which does end with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268c8e5",
   "metadata": {},
   "source": [
    "In python, an attribute and a method have different roles and return values.\n",
    "\n",
    "Attribute:\n",
    "A feature or characteristic of an item is called an attribute which directly delivered you existing information for the object such as its size (like what df.shape do), without executing any steps like calculation. So it does not need parentheses when you visit it.\n",
    "\n",
    "Examples for attributes:\n",
    "df.shape---returns a pair of values which represent the size of a dataset;\n",
    "df.columns---returns the columns' names in the DataFrame.\n",
    "\n",
    "Method:\n",
    "A function which is related to an object is called a method which is usually used for operating, calculating and performing some actions on an object so it does need parentheses when accessing it as arguments inside the parentheses can be taken to return new data.\n",
    "\n",
    "Examples for methods:\n",
    "df.describe()---returns the summary for numeric columns and non-missing values by default;\n",
    "df.head()---returns the first five rows of the DataFrame by default;\n",
    "df.dropna()---removes rows with missing values from the DataFrame.\n",
    "\n",
    "Summarization of Differences:\n",
    "Attributes supply data that has already been stored in an object without computing and modifying, and parentheses are not required for visiting it.\n",
    "Methods perform a task with a function which need to be executed operations on an object, and parentheses are required for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca03a4",
   "metadata": {},
   "source": [
    "6. The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0971478",
   "metadata": {},
   "source": [
    "The following explains the definitions of each of these summary statistics:\n",
    "\n",
    "1.Count\n",
    "Count shows how many values for each variable are non-missing(non-NaN). It gives the number of valid data points in a specific column.\n",
    "For example, if the count of a column is 250, it indicates that there are 250 non-missing values in that column.\n",
    "\n",
    "2.Mean\n",
    "Mean is the arithmetic average of the values in a column. To calculate mean, all the non-missing values should be summed and then divided by the number of non-missing values.\n",
    "For example, if the values in a column are [3, 8, 10, 23], the mean is (3+8+10+23)/4=11.\n",
    "\n",
    "3.Standard Deviation (std)\n",
    "Standard deviation (std) measures how spread out the values in the column are around the mean, which indicates how much the data vary or desperse. The data points would desperse more widely when the standard deviation is larger, and would be closer to the mean when the standard deviation is smaller.\n",
    "\n",
    "4.min\n",
    "The smallest value of a column is called the minimum(min).\n",
    "For example, in a column of values [1.5, 3.0, 3.3, 5.8, 12.9], the minimum value is 1.5.\n",
    "\n",
    "5.25% (First Quatile)\n",
    "The 25th percentile (Q1) is also called the first quatile, and it is the value below which 25% of the data falls. It is the point where 75% of the data points are larger and 25% of the data points are smaller.\n",
    "For example, the 25th percentile in a sorted set of values [1, 2, 5, 7, 9, 11, 12, 14, 16] is 5.\n",
    "\n",
    "6.50% (Median)\n",
    "The 50th percentile is also called the median, which is the middle value of the sorted data. Half of the data points are below the median, and half are above it. Compared to the mean, median can measure the central tendency, which can be less impacted by outliers.\n",
    "For example, in a sorted set of values [1, 2, 3, 4, 5, 6, 7, 8, 9], the median is 5.\n",
    "\n",
    "7.75% (Third Quatile)\n",
    "The 75th percentile (Q3) is also called the third quatile, and it is the value below which 75% of the data falls. It is the point where 25% of the data points are larger and 75% of the data points are smaller.\n",
    "For example, the 75th percentile in a sorted set of values [1, 2, 5, 7, 9, 11, 12, 14, 16] is 12.\n",
    "\n",
    "8.max\n",
    "The largest value of a column is called the maximun(max).\n",
    "For example, in a column of values [1.5, 3.0, 3.3, 5.8, 12.9], the maximum value is 12.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6092e73",
   "metadata": {},
   "source": [
    "7. Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de262148",
   "metadata": {},
   "source": [
    "1) Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8c87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
      "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
      "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
      "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "5    man        True  NaN   Queenstown    no   True  \n",
      "6    man        True    E  Southampton    no   True  \n",
      "7  child       False  NaN  Southampton    no  False  \n",
      "8  woman       False  NaN  Southampton   yes  False  \n",
      "9  child       False  NaN    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca4613",
   "metadata": {},
   "source": [
    "Use Case Example:\n",
    "\n",
    "df.dropna():\n",
    "\n",
    "Use Case: Assume that you want to keep as much data as possible but you also want to eliminate the rows with missing values in any column, then you should use df.dropna() in this situation, which can drop just the impacted rows without affecting the entire column.\n",
    "\n",
    "Example: If the column age contains some missing values and you want to remove rows with any missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff381f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(subset=['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d05ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0          0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1          1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2          1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3          1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4          0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "6          0       1    male  54.0      0      0  51.8625        S   First   \n",
      "7          0       3    male   2.0      3      1  21.0750        S   Third   \n",
      "8          1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9          1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "10         1       3  female   4.0      1      1  16.7000        S   Third   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "0     man        True  NaN  Southampton    no  False  \n",
      "1   woman       False    C    Cherbourg   yes  False  \n",
      "2   woman       False  NaN  Southampton   yes   True  \n",
      "3   woman       False    C  Southampton   yes  False  \n",
      "4     man        True  NaN  Southampton    no   True  \n",
      "6     man        True    E  Southampton    no   True  \n",
      "7   child       False  NaN  Southampton    no  False  \n",
      "8   woman       False  NaN  Southampton   yes  False  \n",
      "9   child       False  NaN    Cherbourg   yes  False  \n",
      "10  child       False    G  Southampton   yes  False  \n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04807b",
   "metadata": {},
   "source": [
    "If using del df['col'] in this situation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10722554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
      "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
      "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
      "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "5    man        True  NaN   Queenstown    no   True  \n",
      "6    man        True    E  Southampton    no   True  \n",
      "7  child       False  NaN  Southampton    no  False  \n",
      "8  woman       False  NaN  Southampton   yes  False  \n",
      "9  child       False  NaN    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ddf2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1474b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex  sibsp  parch     fare embarked   class    who  \\\n",
      "0         0       3    male      1      0   7.2500        S   Third    man   \n",
      "1         1       1  female      1      0  71.2833        C   First  woman   \n",
      "2         1       3  female      0      0   7.9250        S   Third  woman   \n",
      "3         1       1  female      1      0  53.1000        S   First  woman   \n",
      "4         0       3    male      0      0   8.0500        S   Third    man   \n",
      "5         0       3    male      0      0   8.4583        Q   Third    man   \n",
      "6         0       1    male      0      0  51.8625        S   First    man   \n",
      "7         0       3    male      3      1  21.0750        S   Third  child   \n",
      "8         1       3  female      0      2  11.1333        S   Third  woman   \n",
      "9         1       2  female      1      0  30.0708        C  Second  child   \n",
      "\n",
      "   adult_male deck  embark_town alive  alone  \n",
      "0        True  NaN  Southampton    no  False  \n",
      "1       False    C    Cherbourg   yes  False  \n",
      "2       False  NaN  Southampton   yes   True  \n",
      "3       False    C  Southampton   yes  False  \n",
      "4        True  NaN  Southampton    no   True  \n",
      "5        True  NaN   Queenstown    no   True  \n",
      "6        True    E  Southampton    no   True  \n",
      "7       False  NaN  Southampton    no  False  \n",
      "8       False  NaN  Southampton   yes  False  \n",
      "9       False  NaN    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b1e97",
   "metadata": {},
   "source": [
    "The full column of age is deleted for one missing value, which makes the data seriously incomplete.\n",
    "\n",
    "Therefore, in this case, df.dropna() which would not affect the entire column is preferred over using del df['col']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d22f32",
   "metadata": {},
   "source": [
    "2)  Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29020af9",
   "metadata": {},
   "source": [
    "Use Case for del df['col']:\n",
    "\n",
    "When you want to remove an entire column which contains too many missing values and you think this column is not important, you might select del df['col']. This method is more efficient to drop a column which you are certain it has no valuable data for your research, and it prevents dropping rows unnecessarily.\n",
    "\n",
    "Example:\n",
    "\n",
    "When checking the Titanic dataset, you find the deck column contains a large percentage of missing values,  which makes it less useful for your analysis. In this situation, you can decide to drop the entire column by using del df['col'], but not removing rows that have missing values of deck, as removing too many rows would lose other more valuable information in columns like fare, who, or alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3923434",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['deck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a46df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex  sibsp  parch     fare embarked   class    who  \\\n",
      "0         0       3    male      1      0   7.2500        S   Third    man   \n",
      "1         1       1  female      1      0  71.2833        C   First  woman   \n",
      "2         1       3  female      0      0   7.9250        S   Third  woman   \n",
      "3         1       1  female      1      0  53.1000        S   First  woman   \n",
      "4         0       3    male      0      0   8.0500        S   Third    man   \n",
      "5         0       3    male      0      0   8.4583        Q   Third    man   \n",
      "6         0       1    male      0      0  51.8625        S   First    man   \n",
      "7         0       3    male      3      1  21.0750        S   Third  child   \n",
      "8         1       3  female      0      2  11.1333        S   Third  woman   \n",
      "9         1       2  female      1      0  30.0708        C  Second  child   \n",
      "\n",
      "   adult_male  embark_town alive  alone  \n",
      "0        True  Southampton    no  False  \n",
      "1       False    Cherbourg   yes  False  \n",
      "2       False  Southampton   yes   True  \n",
      "3       False  Southampton   yes  False  \n",
      "4        True  Southampton    no   True  \n",
      "5        True   Queenstown    no   True  \n",
      "6        True  Southampton    no   True  \n",
      "7       False  Southampton    no  False  \n",
      "8       False  Southampton   yes  False  \n",
      "9       False    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5e560",
   "metadata": {},
   "source": [
    "3) Discuss why applying del df['col'] before df.dropna() when both are used together could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b023ef",
   "metadata": {},
   "source": [
    "1.Prevent unnecessary rows deletion\n",
    "If you use df.dropna() first, and the column has a large proportion of missing values, and all rows that have missing values in that column will be dropped. As a result, you might lose a great deal of significant data in those columns where there are no missing values.\n",
    "\n",
    "2.Faster and more efficient operation\n",
    "Using del df['col'] to delete a column is easier than using df.dropna() to remove rows in many columns that have missing values. After reducing the size of the dataset, you can improve the efficiency of operations like dropna(), especially when working with huge datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db7bec",
   "metadata": {},
   "source": [
    "4) Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb5506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Before cleanup: Checking the total number of missing values per column\n",
    "before_cleanup = df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18f05645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(before_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4a3e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "Before Cleanup Missing Values Report:\n",
      " survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "After Cleanup Missing Values Report:\n",
      " survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "Shape before cleanup: (891, 14)\n",
      "Shape after cleanup: (712, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check the columns in the dataset\n",
    "print(df.columns)\n",
    "\n",
    "# Before cleanup: Checking the total number of missing values per column\n",
    "before_cleanup = df.isna().sum()\n",
    "\n",
    "# Step 1: Delete columns with a high number of missing values or irrelevant columns\n",
    "# For example, we will drop 'deck' as it has many missing values and is less relevant\n",
    "del df['deck']\n",
    "\n",
    "# Step 2: Drop rows with missing values in key columns such as 'age', 'embarked' and 'embark_town'\n",
    "df_cleaned = df.dropna(subset=['age', 'embarked', 'embark_town'])\n",
    "\n",
    "# After cleanup: Checking the number of missing values per column\n",
    "after_cleanup = df_cleaned.isna().sum()\n",
    "\n",
    "# Shape before and after cleanup\n",
    "before_shape = df.shape\n",
    "after_shape = df_cleaned.shape\n",
    "\n",
    "# Display the reports\n",
    "print(\"Before Cleanup Missing Values Report:\\n\", before_cleanup)\n",
    "print(\"\\nAfter Cleanup Missing Values Report:\\n\", after_cleanup)\n",
    "print(\"\\nShape before cleanup:\", before_shape)\n",
    "print(\"Shape after cleanup:\", after_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df84e28",
   "metadata": {},
   "source": [
    "Justification of Approach:\n",
    "\n",
    "1.Delete the 'deck' Column by using del df['col']: The deck column contains numerous missing values, and it's not really important data unless you are doing specific analysis about the information of deck. Removing this column helps avoid the unnecessary deletion of rows that have valid data in other important columns, and also helps reduce the size of the dataset.\n",
    "\n",
    "2.Drop Rows with Missing Values in Key Columns by using df.dropna(): After deleting the deck column, we drop rows that have missing values in the columns age, embarked and embark_town, which are crucial for survival analysis.\n",
    "\n",
    "Before and After Report:\n",
    "\n",
    "Before Cleanup: The report shows the number of missing values containing in all columns, especially in deck column which has a large number of missing values.\n",
    "\n",
    "After Cleanup: The deck column is removed, and missing values in other columns like age, embarked and embark_town are also cleaned up. The size of the dataset is also shrinked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d3ad8",
   "metadata": {},
   "source": [
    "8. Give brief explanations in your own words for any requested answers to the questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7998b0",
   "metadata": {},
   "source": [
    "Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fe4dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f5d84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min        25%   50%    75%       max\n",
      "sex                                                                        \n",
      "female  314.0  44.479818  57.997698  6.75  12.071875  23.0  55.00  512.3292\n",
      "male    577.0  25.523893  43.138263  0.00   7.895800  10.5  26.55  512.3292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by Passenger Gender (sex) and describe fare\n",
    "grouped_description = df.groupby(\"sex\")[\"fare\"].describe()\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad1096",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "df.groupby(\"who\"): This part groups the dataset by the sex column (Passenger Gender). Each unique value in sex will be a group (male and female).\n",
    "\n",
    "[\"fare\"]: After grouping, this selects the fare column for analysis.\n",
    "\n",
    ".describe(): This function generates summary statistics for the age column within each sex. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d66ed",
   "metadata": {},
   "source": [
    "Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba8ff7c",
   "metadata": {},
   "source": [
    "In df.describe(), the dataset is considered as a whole, the count represents the number of non-missing values for each column.\n",
    "\n",
    "In df.groupby(\"col1\")[\"col2\"].describe(), the count represents the number of non-missing values in col2 from each group of col1. Each group has its own count, and missing values in col2 are excluded from the count in that group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835ee2b",
   "metadata": {},
   "source": [
    "Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c3d09",
   "metadata": {},
   "source": [
    "A) Forget to include import pandas as pd in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26b761a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d7143",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "It looks like the pandas library has not been imported. To resolve the NameError: name 'pd' is not defined, you need to ensure that the pandas library is imported before using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b0b94b",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a0d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Example: Group by Passenger Class (pclass) and describe Age\n",
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f16a55",
   "metadata": {},
   "source": [
    "B) Mistype \"titanic.csv\" as \"titanics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0b017a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitanics.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('titanics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327d724",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "It seems like there's a typo in the file path or file name you are using. The correct file name is titanic.csv, not titanics.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149802aa",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e56ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the correct URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a879d4a",
   "metadata": {},
   "source": [
    "C) Try to use a dataframe before it's been assigned into the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f18bf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "DF.groupby('col1')['col2'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee0d42",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "The error you’re seeing suggests that there’s a mismatch in variable naming. The correct variable name is df (lowercase), but in the error, it's showing DF (uppercase), which has not been defined.\n",
    "\n",
    "Python is case-sensitive, so make sure that you're consistently using df (lowercase) as the variable name throughout your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be21ab7",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1cccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the correct URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)  # Ensure the variable is 'df' in lowercase\n",
    "\n",
    "# Example: Group by Passenger Class (pclass) and describe Age\n",
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770b7fe",
   "metadata": {},
   "source": [
    "D) Forget one of the parentheses somewhere the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6013fa7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3497299412.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv('titanic.csv'\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778520d",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "A SyntaxError: incomplete input usually means there’s an issue with how the code is written, like a missing parenthesis, quotation mark, or an incomplete statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026721fd",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa225eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the correct URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url) #don't forget the parenthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c9674",
   "metadata": {},
   "source": [
    "E) Mistype one of the names of the chained functions with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5341eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101/1509504041.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "df.group_by(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb5fc7",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "The error you're seeing, 'DataFrame' object has no attribute 'group_by', suggests that there’s a typo in the method name. The correct method is groupby (no underscore), not group_by."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81bbc2e",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69e6d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a8022",
   "metadata": {},
   "source": [
    "F) Use a column name that's not in your data for the groupby and column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a50de96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: Age'"
     ]
    }
   ],
   "source": [
    "df.groupby(\"sex\")[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8468d6",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "The error you're encountering, KeyError: 'Column not found: Age', suggests that the column name you are using (\"Age\") does not match any of the columns in the dataset. In the Titanic dataset, column names are case-sensitive, and the column name for age is actually \"age\" (all lowercase), not \"Age\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91cb69",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "168da165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()  # 'age' should be lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46ef63",
   "metadata": {},
   "source": [
    "G) Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6076ab32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msex\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "df.groupby(sex)[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13fa542",
   "metadata": {},
   "source": [
    "Feedback from chatgpt:\n",
    "The NameError: name 'sex' is not defined occurs because 'sex' is likely being referenced without using the proper syntax for accessing a column in a pandas DataFrame.\n",
    "\n",
    "In pandas, you need to use df['sex'] (not just sex) to reference the \"sex\" column from the DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51852170",
   "metadata": {},
   "source": [
    "code fixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c1d411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec486d",
   "metadata": {},
   "source": [
    "About the speed and efficiency of troubleshooting, chatgpt and google both have their advantages.\n",
    "\n",
    "chatgpt offers instant reponses especially for those common coding problems. If the question you ask is straightforward, then chatgpt can quikly analyse and give you a solution immediately. However, google always returns lots of materials, so it needs you to look through them and find the answer by yourself, which will take more time than using chatgpt, but google would be better for those who want to deeper study and explore, and chatgpt is just a learning tool which provides direct explanation.\n",
    "\n",
    "Therefore, as learners, we should use chatgpt and google for different purposes, but the same purpose using them is to learn more and get progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d81fbb",
   "metadata": {},
   "source": [
    "9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11617247",
   "metadata": {},
   "source": [
    "Yes, i interacted with chatgpt and also talked about the material after lecture with my friends, but i haven't found a time to go to the OH cuz my timetable always conflicts with it, but i will try to adjust it as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b6aaa",
   "metadata": {},
   "source": [
    "link for Q1-Q7 with chatgpt:\n",
    "https://chatgpt.com/share/845d8ae1-3b25-4b33-8d46-bd09dde614b0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc14dd",
   "metadata": {},
   "source": [
    "link for Q8 with chatgpt:\n",
    "https://chatgpt.com/share/d20b3833-37c1-4d74-83b4-6d15c4161f00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ccbfff",
   "metadata": {},
   "source": [
    "Abstract for Q1-Q7 with chatgpt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f3566",
   "metadata": {},
   "source": [
    "Summary of Interactions with ChatGPT (Including Code)\n",
    "1. Loading and Inspecting the Titanic Dataset\n",
    "We worked with the Titanic dataset from the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786da504",
   "metadata": {},
   "source": [
    "You initially wanted to load and inspect the dataset for missing values, and here’s the code for doing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Checking for missing values in the dataset\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f15202",
   "metadata": {},
   "source": [
    "This code loads the dataset and prints the number of missing values in each column. You can use this to get a sense of where the missing data is concentrated.\n",
    "\n",
    "2. Explanation of \"Attributes\" and \"Methods\" in Python\n",
    "We discussed the difference between attributes and methods in Python:\n",
    "\n",
    "Attributes: These are properties of an object that provide stored information. For example, df.shape tells you the number of rows and columns in a DataFrame but does not require parentheses.\n",
    "\n",
    "Methods: These are functions associated with an object that perform actions or computations. For example, df.describe() computes summary statistics for each column and requires parentheses to execute.\n",
    "\n",
    "3. Definitions of Summary Statistics from df.describe()\n",
    "I explained the following summary statistics from df.describe():\n",
    "\n",
    "Count: The number of non-missing values.\n",
    "Mean: The arithmetic average of the values.\n",
    "Std: The standard deviation, a measure of spread or variation.\n",
    "Min: The smallest value.\n",
    "25%: The first quartile, where 25% of the data lies below this value.\n",
    "50% (Median): The middle value of the data.\n",
    "75%: The third quartile, where 75% of the data lies below this value.\n",
    "Max: The largest value in the dataset.\n",
    "These summary statistics help to understand the distribution of numeric data in the DataFrame.\n",
    "\n",
    "4. Handling Missing Data: Comparison of df.dropna() vs. del df['col']\n",
    "We explored the two primary methods for handling missing data:\n",
    "\n",
    "df.dropna(): This method removes rows that contain missing values. You might prefer this approach when you want to retain as much of the dataset as possible, while removing incomplete observations.\n",
    "\n",
    "Example Use Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(subset=['age', 'embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b36f2",
   "metadata": {},
   "source": [
    "del df['col']: This deletes an entire column. You would use this if a column has too many missing values or is not relevant to your analysis.\n",
    "\n",
    "Example Use Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e121e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['deck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d275c0",
   "metadata": {},
   "source": [
    "5. Combination of df.dropna() and del df['col']\n",
    "We discussed using both del df['col'] and df.dropna() together for cleaning the dataset. The order is important because deleting irrelevant columns with high missing values before removing rows allows you to keep more useful data.\n",
    "\n",
    "Why delete the column first?\n",
    "\n",
    "Avoiding unnecessary row deletions: If a column like deck has many missing values, using df.dropna() first would remove rows that might contain important data in other columns like age or embarked.\n",
    "Justification for Approach:\n",
    "Step 1: Delete irrelevant columns (e.g., deck) that have many missing values.\n",
    "Step 2: Use df.dropna() to remove rows with missing values in critical columns (e.g., age and embarked).\n",
    "6. Final Code Example for Cleaning the Dataset\n",
    "Here’s the final code that performs the cleaning by first deleting the deck column and then removing rows with missing values in key columns like age and embarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Before cleanup: Checking the total number of missing values per column\n",
    "before_cleanup = df.isna().sum()\n",
    "\n",
    "# Step 1: Delete the 'deck' column (high number of missing values, less relevant to analysis)\n",
    "if 'deck' in df.columns:\n",
    "    del df['deck']\n",
    "\n",
    "# Step 2: Drop rows with missing values in key columns such as 'age' and 'embarked'\n",
    "df_cleaned = df.dropna(subset=['age', 'embarked'])\n",
    "\n",
    "# After cleanup: Checking the number of missing values per column\n",
    "after_cleanup = df_cleaned.isna().sum()\n",
    "\n",
    "# Shape before and after cleanup\n",
    "before_shape = df.shape\n",
    "after_shape = df_cleaned.shape\n",
    "\n",
    "# Display the results\n",
    "print(\"Before Cleanup Missing Values Report:\\n\", before_cleanup)\n",
    "print(\"\\nAfter Cleanup Missing Values Report:\\n\", after_cleanup)\n",
    "print(\"\\nShape before cleanup:\", before_shape)\n",
    "print(\"Shape after cleanup:\", after_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff2d6a",
   "metadata": {},
   "source": [
    "Before and After Report\n",
    "Before Cleanup:\n",
    "\n",
    "A report of missing values per column before any cleanup is performed.\n",
    "The deck column typically contains many missing values, which would justify its deletion.\n",
    "After Cleanup:\n",
    "\n",
    "After deleting the deck column and using df.dropna() to remove rows with missing values in age and embarked, we get a cleaner dataset with fewer missing values.\n",
    "Shape Comparison:\n",
    "\n",
    "Before Cleanup: The dataset will have its original shape.\n",
    "After Cleanup: The dataset will have fewer rows, depending on how many rows were removed due to missing data.\n",
    "\n",
    "Conclusion:\n",
    "This summary captures our discussion on cleaning a dataset using del df['col'] and df.dropna(), explaining the rationale behind the approach and providing detailed Python code examples for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37574d",
   "metadata": {},
   "source": [
    "Abstract for Q8 with chatgpt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff0b25",
   "metadata": {},
   "source": [
    "Here’s a complete summary of our exchanges along with the relevant code snippets that we've discussed during this session:\n",
    "\n",
    "Initial Request:\n",
    "You asked for an example using the Titanic dataset with the following code format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"col1\")[\"col2\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37322b44",
   "metadata": {},
   "source": [
    "First Example: Grouping by Passenger Class and Describing Age\n",
    "We used the Titanic dataset and grouped the passengers by their class (pclass), then described the age column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d34532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by Passenger Class (pclass) and describe Age\n",
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "\n",
    "# Print the grouped description\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59831218",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "groupby(\"pclass\"): Groups the dataset by passenger class.\n",
    "[\"age\"].describe(): Computes descriptive statistics (like count, mean, std, min, max) for the age column within each passenger class.\n",
    "Difference Between df.describe() and Grouped Descriptions\n",
    "You wanted to understand the difference between the count in df.describe() and df.groupby(\"col1\")[\"col2\"].describe().\n",
    "\n",
    "df.describe() shows summary statistics for each column across the whole dataset. The count represents the number of non-missing values in each column.\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe() groups the dataset by col1 and then shows descriptive statistics for col2 within each group. The count here represents the number of non-missing values for col2 within each group defined by col1.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show descriptive statistics for the whole dataset\n",
    "print(df.describe())\n",
    "\n",
    "# Show descriptive statistics for age, grouped by pclass\n",
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de782a",
   "metadata": {},
   "source": [
    "Resolving Errors and Common Mistakes\n",
    "During our exchanges, we encountered several errors and resolved them:\n",
    "\n",
    "NameError: name 'pd' is not defined\n",
    "Solution: Ensure that pandas is imported at the top of your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f446a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120aa8e7",
   "metadata": {},
   "source": [
    "FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'\n",
    "Solution: Correct the file name to titanic.csv and use the correct URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d30ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63904ca3",
   "metadata": {},
   "source": [
    "NameError: name 'DF' is not defined\n",
    "Solution: Ensure consistent variable naming (use lowercase df):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83f5d1",
   "metadata": {},
   "source": [
    "AttributeError: 'DataFrame' object has no attribute 'group_by'\n",
    "Solution: Use groupby instead of group_by (no underscore):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description = df.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062a985",
   "metadata": {},
   "source": [
    "KeyError: 'Column not found: Age'\n",
    "Solution: Ensure the column names are spelled correctly and match the dataset (e.g., use lowercase \"age\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a36cc",
   "metadata": {},
   "source": [
    "NameError: name 'sex' is not defined\n",
    "Solution: Reference columns correctly by using df['sex'] instead of just sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_description = df.groupby(\"sex\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3f9e4",
   "metadata": {},
   "source": [
    "Final Corrected Code Example (with Grouping by Sex and Age Descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc53c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column\n",
    "grouped_description = df.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "# Print the grouped description\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801fe29",
   "metadata": {},
   "source": [
    "This code groups the Titanic dataset by the sex column and describes the age for males and females separately.\n",
    "\n",
    "Summary:\n",
    "Throughout the conversation, we:\n",
    "\n",
    "Worked on summarizing data using the groupby method and describe function.\n",
    "Discussed differences between global and grouped descriptive statistics.\n",
    "Resolved various errors such as incorrect imports, file names, and column references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
